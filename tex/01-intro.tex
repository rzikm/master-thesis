\chapter{Introduction}

The internet, as we know it today, heavily relies on the use of the HTTP protocol. Is it used not
only by web browsers for interacting with web applications, but it may also be used at the server
side for communication between individual nodes in a cluster. Such use of HTTP is commonly seen in,
e.g., microservices architecture. Last but not least, HTTP is also used as a transport medium for
RESTful web APIs and technologies such as gRPC and GraphQL.

The latest version of the HTTP protocol is HTTP/2, published in 2015~\cite{rfc7540}. HTTP/2 improved
on its predecessor HTTP/1.1~\cite{rfc7230} by introducing request multiplexing over a single TCP
connection, header compression, and server-push features. These features led to reduced loading
times of web pages and generally improved the efficiency of the web~\cite{deSaxce2015}.

\section{Remaining Performance Issues in HTTP/2}

HTTP/2 does not solve all the performance issues HTTP/1.1 had. HTTP/2 introduced new features and
changes only to the topmost layer of the HTTP stack, and these changes could not address the
performance limiting phenomenons caused by the layers underneath. For the context of this thesis,
the following two performance problems are the most relevant.

\subsection*{Head-of-Line Blocking}

Request multiplexing was introduced in HTTP/2 to reduce the number of web servers' resources
required to serve requests made by web browsers. Because modern web pages are composed of many parts
(HTML, images, Javascript files, CSS style sheets), web browsers have to make multiple HTTP requests
to load the page. In HTTP/1.1, multiple parallel HTTP connections were made to download individual
parts of the webpage, one connection per HTTP request. In HTTP/2, a single connection can be used to
make multiple HTTP requests in parallel. Although this change improved HTTP's performance, its
current design is limited by a phenomenon known as \textit{\gls{head-of-line-blocking}}.

The individual HTTP frames which make up the HTTP requests are interleaved and transferred over TCP
in a single stream of data. When a TCP packet carrying part of this stream is lost, delivery of all
following packets is delayed until the lost packet is retransmitted. This will cause a delay in all
HTTP requests currently in progress, even if the lost packet contained data belonging only to a
single HTTP request. More information on head-of-line blocking can be found, e.g., on a dedicated
Wikipedia page~\cite{wiki:head-of-line-blocking}.

\subsection*{HTTPS Connection Establishment Latency}

HTTPS~\cite{rfc2818} is an extension to HTTP, which makes the connection encrypted by inserting the
TLS protocol layer between HTTP and TCP. Therefore, establishing an HTTPS connection requires first
establishing a TCP connection --- performing the three-way handshake --- and then performing another
separate handshake for the TLS layer. As can be seen on the illustration in
\autoref{fig:https-packets}, a minimum of three round trips is needed before the HTTP request can be
even sent.

\begin{myFigure} {fig:https-packets} {Packets sent during HTTPS connection establishment}

  \resizebox{0.8\linewidth}{!}{\input{img/01-https-handshake.pdf_tex}}

\end{myFigure}

More and more websites enforce the use of HTTPS in order to protect the privacy of their users. In
August 2020, 96 out of the top 100 viewed websites actively redirect to HTTPS, and more than 75\% of
all network traffic from the Chrome web browser used HTTPS~\cite{googleTransparency}. Even server to
server communication in the cloud is trending towards HTTPS to protect against partially compromised
networks. With HTTPS becoming the norm, almost all connections suffer from the increased latency
caused by the additional TLS handshake.

\section{HTTP/3 and QUIC}

The next version of the HTTP protocol --- HTTP/3~\cite{draft-ietf-quic-http} --- addresses the issues
mentioned above by replacing the TCP and TLS layers with a brand new UDP-based protocol named
QUIC\footnote{Originally intended as the acronym for Quick UDP Internet Connection. However, it has
been changed to be the protocol's actual name during the standardization process}. The QUIC protocol
features allow moving multiplexing capability from the application layer into the transport layer of
the HTTP protocol stack. The responsibilities and relationships between protocols on HTTP/2 and
HTTP/3 stacks are illustrated in \autoref{fig:http2-vs-http3-stack}.

\begin{myFigure} {fig:http2-vs-http3-stack} {Comparison between HTTP/2 and HTTP/3 protocol stacks}

  \input{img/01-http2-vs-http3-stack.pdf_tex}

\end{myFigure}

Although QUIC development is tied with that of HTTP/3, it is designed as a general-purpose transport
layer protocol that can be used for other application-layer protocols. The following points
summarize the main improvements of QUIC over TCP+TLS:

\begin{itemize}

    \litem{Stream multiplexing} QUIC provides an abstraction of multiple streams of data multiplexed
on a single connection. Moreover, because QUIC itself also implements loss detection, packet loss
can be managed in a way that reduces the scope of the \gls{head-of-line-blocking} problem described
above to the single affected stream.

    \litem{Faster connection establishment} QUIC also performs TLS handshake, but it does so in
parallel with the base protocol's handshake. The combined handshake requires fewer round-trips and
is, therefore, faster than the combination of TCP and TLS\@.

    QUIC also supports opt-in \gls{0rtt} from TLS 1.3. The 0-RTT mode of operation allows a client
to cache some session information, allowing it to send application layer data with the first packet
in future connections to the same server. 0-RTT effectively reduces the latency by another round
trip but makes connections vulnerable to repeat attacks. A more detailed description of 0-RTT can be
found online, e.g., on Cloudflare's blog~\cite{cloudflare-0rtt}.

    \litem{Always encrypted} TLS handshake is a mandatory part of connection establishment, and
encryption, therefore, cannot be turned off. This makes QUIC secure-by-default.

    \litem{Separating connection identity from peer's IP address} QUIC protocol does not use peers'
IP addresses to identify connections but instead uses Connection IDs, which are 8 to 20-byte
sequences negotiated during connection establishment.

    This makes QUIC very attractive for mobile devices, which can change IP addresses due to
switching between Wi-Fi and cellular data network. In TCP and --- by extension --- HTTP/2, the existing
connection must be terminated, and a new connection established from the new IP address. QUIC, on
the other hand, can migrate the connections in a way that is transparent to the application layer.

    This feature also enables QUIC extensions like Multipath
QUIC~\cite{draft-deconinck-quic-multipath-04}, which allows the simultaneous use of multiple network
interfaces for a single connection to achieve greater throughput.

\end{itemize}

As of August 2020, the specifications of HTTP/3 and QUIC are still at the draft stage, but the
standardization process is believed to be very close to complete. There are already multiple
implementations of QUIC being developed based on the draft versions of the standard. These
implementations are backed by big companies such as Google, Cloudflare, Facebook, and Microsoft.

Experiments with these implementations allowed early performance comparison between HTTP/3 and
HTTP/2, yielding promising results. In 2015, the Chromium team's experimental implementation showed
a 3\% improvement in mean page load time and 30\% fewer rebuffer events when watching YouTube
videos~\cite{Wilk2015}. Cloudflare launched preliminary support for HTTP/3 in April 2020 and has
measured a 12.4\% decrease in the \textit{time to the first byte} metric~\cite{Tellakula2020}, which
is consistent with the QUICs promise of reduced latency. In measurements done by Orange Labs, QUIC
protocol significantly outperforms TCP in unstable networks such as wireless mobile
networks~\cite{Cook2017}.

\section{Support for QUIC in \dotnet{}}

Microsoft's \dotnet{} development team has long-term plans to provide full support for QUIC and
HTTP/3 in \dotnet{}. Support for HTTP/3 should be completely transparent to users because the
implementation of \class{HttpClient} automatically chooses the best available HTTP
version~\cite{HttpClientDocs}. However, since QUIC can be used to build other protocols than HTTP/3,
its implementation will be exposed via public classes residing most likely inside the
\namespace{System.Net.Quic} namespace.

The QUIC support has been initially intended for the \dotnet{}~5 release planned for November 2020.
However, it turned out that the standardization process would not be completed in time for QUIC to
be implemented for the release. \dotnet{}~5, therefore, ships with only a preview (non-production
ready) HTTP/3 and QUIC support. A production-ready HTTP/3 and QUIC implementation was postponed
until \dotnet{}~6 release.

\subsection*{Existing QUIC Implementation in \dotnet{}}

The work-in-progress implementation of QUIC is still present in the master development branch of the
\dotnet{} runtime repository~\cite{dotnetGithub} but has been made accessible only internally. This
implementation is a wrapper around the \libmsquic{} library~\cite{msquicGithub}, which is a C
implementation of QUIC developed by Microsoft. The \libmsquic{} library is designed for
high-performance scenarios and has been recently made open-source.

The decision to use \libmsquic{} as the QUIC protocol implementation is not final. There are
compelling arguments for implementing the QUIC protocol in managed \dotnet{} code --- and, more
specifically, in \csharp{} --- for the production release.

The existing QUIC implementation in \dotnet{} uses a layer of indirection which allows multiple
implementations to exist side by side. In theory, this makes it possible to switch between QUIC
implementations at runtime, allowing performance comparisons between candidate QUIC implementations.

\subsection*{Motivation for Implementing QUIC in Managed Code}

Code written in ahead-of-time compiled languages such as C or C++ (referred to as
\textit{\gls{native-code}}) is likely to be faster than code written in \dotnet{} languages
(referred to as \textit{\gls{managed-code}}), which rely on the just-in-time compilation. However,
there are other aspects than raw performance to be considered when deciding to use native libraries
such as \libmsquic{}:

\begin{itemize}

    \litem{Cross-platform compatibility/availability} The \dotnet{} platform officially supports
multiple versions of Windows, macOS, and several Linux distributions. If the native library does not
support all these platforms, then the implementation must use an alternative library on other
platforms, introducing more complexity into the codebase and possible incompatibilities between
platforms.

    \litem{Support for different library versions} Currently, no native libraries that managed
\dotnet{} libraries depend on are part of the \dotnet{} distribution. Instead, \dotnet{} runtime
expects that the library is already installed on the target machine and can be dynamically loaded.
There is no way to enforce a specific version of the library, which means that the \dotnet{} code
must work correctly with multiple versions of the native library.

    \litem{Maintainability} Maintenance of the interop code requires the developer to read and
understand the language in which the native library is written. Debugging the code around the
language boundaries can be difficult if the necessary tooling for mixed-language debugging is not
available.

    \litem{Library's API} One of the aspects which greatly influences the resulting performance is
the similarity between the public API of the \dotnet{} library and the API of the native library.
Some aspects are the following:

    \begin{itemize}
      \item Event-based (using callbacks) vs.\ method based
      \item Blocking vs.\ non-blocking
      \item Synchronous vs.\ asynchronous
      \item Which side allocates memory buffers
    \end{itemize}

    \Gls{managed-code} needs to translate the differences between APIs, which may result in
noticeable performance overhead and even negate the performance gained from the native library's
use.

    \litem{Overhead of interop calls} When execution transitions between managed and unmanaged code,
the runtime must ensure the correct behavior of exceptions and garbage collector. The cost of the
so-called managed-to-native transition is relatively small. However, it may be noticeable when the
transition occurs very frequently.

    \litem{Future development} Exposing new features from newer versions of the native library can
be problematic because the code needs to work with older versions of the library.

\end{itemize}

In the past, the \dotnet{} development team has encountered multiple problems with the
\libcurl~\cite{curlGithub} library, which was used to implement HTTP request handling on macOS and
Linux. Different Linux distributions contained different versions of the \libcurl{} library and,
therefore, supported different features and had different bugs. The \dotnet{} development team had
to expend many resources to make sure the \gls{managed-code} written by other \dotnet{} developers
behaved consistently on all platforms.

Starting with \dotnet{} Core~2.1, the default implementation of HTTP request handling does not rely
on native libraries like \libcurl{}. Instead, the functionality has been rewritten in pure managed
code on top of sockets. This implementation offered better performance and consistent behavior
across all \dotnet{} platforms~\cite{SocketsHttpHandlerDocs}.

\section{Goals of this Thesis}\label{sec:01-goals}

The reasons mentioned in the previous section motivated Microsoft developers to consider
implementing QUIC in purely managed \csharp{} code. Before the final decision on which
implementation of QUIC will be used, it is necessary to investigate the performance characteristics
of managed QUIC implementation. This thesis seeks to create a partial implementation of QUIC whose
performance can be analyzed and --- if the managed implementation approach is found viable --- can form
the basis of the production QUIC implementation in future \dotnet{} versions.

Because this thesis's work can potentially become part of future \dotnet{}~6 release, the QUIC
implementation development will occur inside a development branch of the \dotnet{} runtime
repository. The result should be a compilable branch of the runtime, which exposes the QUIC API for
other \dotnet{} developers to use.

We have mentioned that the design of the QUIC API was interrupted early. Although the current
version does not expose all the QUIC protocol features, it is sufficient for evaluating our
implementation. This thesis will, therefore, avoid making any modifications to the API\@.

Implementing the full QUIC specification is outside the scope of a master thesis. Fortunately, to
evaluate the managed QUIC implementation's performance, many parts of the specification can be
omitted from our prototype. Therefore, this thesis will focus on the functionality needed to fully
support simple scenarios and leave out advanced features such as connection migration.

Because we do not expect readers to be thoroughly familiar with the QUIC protocol specification and
all its features, we will present an overview of the protocol in \autoref{chap:02-quic} and defer
the selection of the protocol features we will implement in this thesis to the beginning of the
analysis in \autoref{chap:03-analysis}. However, the implementation design should be such that the
rest of the specification can be implemented in the future.

\todo{these two paragraphs have changed}

It would make sense to evaluate our QUIC implementation's functionality by providing a partial
implementation of HTTP/3. However, even supporting the most straightforward GET requests would be
too complicated. Instead, we will implement a simple application in which server will echo all data
back to the client.

Because the indirect nature of the existing QUIC API could be used to alternate between
\libmsquic{}-based QUIC and our QUIC implementation at runtime. This would allow us to create a
benchmarking application to compare the performance of the two QUIC implementations. A small step
from there would allow us to compare the performance of the two QUIC implementations with that of
TCP+TLS-based \class{SslStream}. This benchmarking will be an optional goal of this thesis.

\subsection*{Summary of the Goals}

\todo{small changes in goals were done}

The following list summarizes the goals of this thesis presented in the previous subsection.

\begin{enumerate}

  \item Select a sufficient subset of QUIC specification needed to support the most basic data
  transfer and implement it inside \dotnet{} runtime codebase.

  \item Allow switching between the new managed implementation and the existing \libmsquic{}-based one.

  \item Evaluate the managed QUIC implementation by using it to implement a simple client-server
echo application.

  \item \textit{(optional)} Try to compare the performance of the new implementation with the
previous \libmsquic{}-based one and with TCP+TLS-based \class{SslStream}.

\end{enumerate}
